# LlamaFactory配置 - 用于Step 3蒸馏训练
# 使用方法: llamafactory-cli train configs/llamafactory_distill.yaml

### 模型配置
model_name_or_path: ./models/foundation  # Student初始化模型路径 (或./models/sft)
trust_remote_code: true

### 数据配置
dataset: distill_train  # 需要在data/dataset_info.json中定义
template: qwen  # Qwen模型模板
cutoff_len: 2048
max_samples: null
overwrite_cache: true
preprocessing_num_workers: 8

### 训练配置
stage: sft
do_train: true
finetuning_type: full  # 全参数微调

### 蒸馏参数 (自定义)
# 注意: LlamaFactory原生不支持蒸馏，需要修改或使用自定义trainer
# 这里提供标准SFT配置，可以作为baseline

### 输出配置
output_dir: ./models/checkpoints/distill_llamafactory
overwrite_output_dir: true

### 超参数
per_device_train_batch_size: 2
gradient_accumulation_steps: 8
learning_rate: 5.0e-6
num_train_epochs: 2
lr_scheduler_type: cosine
warmup_ratio: 0.1

### 优化器
optim: adamw_torch
adam_beta1: 0.9
adam_beta2: 0.999
weight_decay: 0.01

### 保存和日志
save_steps: 1000
logging_steps: 10
save_total_limit: 3
bf16: true  # 使用bfloat16

### 评估
val_size: 0.1
evaluation_strategy: steps
eval_steps: 1000
per_device_eval_batch_size: 4

### 其他
ddp_timeout: 180000000
gradient_checkpointing: true  # 节省显存
report_to: tensorboard

### Deepspeed (可选，多GPU训练)
# deepspeed: configs/ds_config_zero2.json
